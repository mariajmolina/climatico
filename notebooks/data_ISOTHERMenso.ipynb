{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation for ENSO events and their vertical depth\n",
    "\n",
    "Compute ONI values, then extract corresponding tropical Pacific region SSTs for ENSO events. Save as netCDFs for future use. Save El Nino, La Nina, and corresponding experiment climatology (for computing ENSO event anomalies).\n",
    "\n",
    "**Figure by: Maria J. Molina, NCAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from climatico import enso\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from climatico.util import weighted_mean, pacific_lon\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import directory_figs, directory_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THEDEPTH = 'DEPTH_OF_18C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_enso_spatial(ds, indices, ds_oni, year1, year2, cutoff, filevar='SST'):\n",
    "    \"\"\"\n",
    "    Use the input seasonal file ('QS-DEC') and precomputed Nino-index to extract Nino(a) \n",
    "    event indices in time array of SST file.\n",
    "    Then extract the variable associated with the Nino(a) events. These focus on DJF months.\n",
    "    \n",
    "    Args:\n",
    "        ds (xarray data array): Seasonal variable to filter for plotting \n",
    "                                    (e.g., ds.resample(time='QS-DEC').mean(skipna=True)).\n",
    "        indices (numpy array): ONI values as numpy array \n",
    "                                    (e.g., control_nino.resample(time='QS-DEC').mean(skipna=True).values).\n",
    "        ds_oni (xarray data array): ONI seasonal xarray \n",
    "                                    (e.g., control_nino.resample(time='QS-DEC').mean(skipna=True)).\n",
    "        year1 (int): First year for range filtering.\n",
    "        year2 (int): Second year for range filtering.\n",
    "        cutoff (float): Cutoff of ENSO events. E.g., +/-0.5 for ONI.\n",
    "        filevar (str): Variable name for input ds. Defaults to ``SST.``\n",
    "    \"\"\"\n",
    "    # do checks\n",
    "    check1 = ds[filevar].isel(TIME=np.where(indices>=cutoff)[0])[(ds[filevar].isel(TIME=np.where(indices>=cutoff)[0])['TIME'].dt.month==12)].coords['TIME']\n",
    "    check2 = ds_oni.isel(time=np.where(indices>=cutoff)[0])[(ds_oni.isel(time=np.where(indices>=cutoff)[0])['time'].dt.month==12)].coords['time']\n",
    "    assert np.all(check1.values==check2.values), \"Nino events don't match\"\n",
    "    print(\"Nino check passed\")\n",
    "    \n",
    "    check1 = ds[filevar].isel(TIME=np.where(indices<=cutoff)[0])[(ds[filevar].isel(TIME=np.where(indices<=cutoff)[0])['TIME'].dt.month==12)].coords['TIME']\n",
    "    check2 = ds_oni.isel(time=np.where(indices<=cutoff)[0])[(ds_oni.isel(time=np.where(indices<=cutoff)[0])['time'].dt.month==12)].coords['time']\n",
    "    assert np.all(check1.values==check2.values), \"Nina events don't match\"\n",
    "    print(\"Nina check passed\")\n",
    "    \n",
    "    ### nino\n",
    "    # filter for djf quarters\n",
    "    sv_indices = ds[filevar].isel(TIME=np.where(indices>=cutoff)[0])[(ds[filevar].isel(TIME=np.where(indices>=cutoff)[0])['TIME'].dt.month==12)]\n",
    "    # filter for correct year range\n",
    "    sv_indices = sv_indices[(sv_indices['TIME'].dt.year>=year1)&(sv_indices['TIME'].dt.year<=year2)]\n",
    "    # take spatial mean for plotting\n",
    "    nino = sv_indices.mean(dim='TIME')\n",
    "    print(\"Nino done\")\n",
    "\n",
    "    ### nina\n",
    "    # filter for djf quarters\n",
    "    sv_indices = ds[filevar].isel(TIME=np.where(indices<=cutoff)[0])[(ds[filevar].isel(TIME=np.where(indices<=cutoff)[0])['TIME'].dt.month==12)]\n",
    "    # filter for correct year range\n",
    "    sv_indices = sv_indices[(sv_indices['TIME'].dt.year>=year1)&(sv_indices['TIME'].dt.year<=year2)]\n",
    "    # take spatial mean for plotting\n",
    "    nina = sv_indices.mean(dim='TIME')\n",
    "    print(\"Nina done\")\n",
    "    return nino, nina\n",
    "\n",
    "def pop_lon_nino34():\n",
    "    \"\"\"\n",
    "    Extract mask for the pacslab region. Mask contains ones and nans.\n",
    "    \"\"\"\n",
    "    for_lon = xr.open_dataset(f'{directory_data}b.e11.B1850LENS.f09_g16.FWAtSalG02Sv.pop.h.SST.000101-005012.nc')\n",
    "    mask = for_lon['SST'].where((for_lon['TLAT']<10) & (for_lon['TLAT']>-10) & (for_lon['TLONG']>160) & (for_lon['TLONG']<-80+360), \n",
    "                                 drop=False).isel(z_t=0, time=0).values\n",
    "    return np.where(np.isnan(mask), np.nan, 1)\n",
    "\n",
    "def compute_iso(twodim_array, mask):\n",
    "    \"\"\"\n",
    "    Create array of depth of isotherm using 3d iso array and 2d mask.\n",
    "    Args:\n",
    "        twodim_array (numpy array): Isotherm values.\n",
    "        mask (numpy array): Mask from pop_lon_indx.\n",
    "    Returns:\n",
    "        One dimensional array across Pacific slab region.\n",
    "    \"\"\"\n",
    "    temp = (twodim_array[:,:] * mask[:,:]) * 0.01\n",
    "    temp = np.nanmean(temp, axis=0)\n",
    "    return temp[~np.isnan(temp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSTs\n",
    "file_g02sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalG02Sv.pop.h.SST.*.nc'\n",
    "file_g04sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalG04Sv.pop.h.SST.*.nc'\n",
    "file_p02sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalP02Sv.pop.h.SST.*.nc'\n",
    "file_p04sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalP04Sv.pop.h.SST.*.nc'\n",
    "file_psalt = 'b1d.e11.B1850LENS.f09_g16.FWPaSalP04Sv.pop.h.SST.*.nc'\n",
    "file_cntrl = 'b1d.e11.B1850C5CN.f09_g16.005.pop.h.SST.*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of filenames to do this for:\n",
    "\n",
    "# grab isotherms\n",
    "iso_g02sv = xr.open_dataset(f'{directory_data}iso20c_FWAtSalG02Sv.nc')\n",
    "iso_g02sv = iso_g02sv.sel(TIME=slice(cftime.DatetimeNoLeap(200, 1, 1, 0, 0),cftime.DatetimeNoLeap(501, 1, 1, 0, 0)))\n",
    "\n",
    "iso_g04sv = xr.open_dataset(f'{directory_data}iso20c_FWAtSalG04Sv.nc')\n",
    "iso_g04sv = iso_g04sv.sel(TIME=slice(cftime.DatetimeNoLeap(200, 1, 1, 0, 0),cftime.DatetimeNoLeap(501, 1, 1, 0, 0)))\n",
    "\n",
    "iso_p02sv = xr.open_dataset(f'{directory_data}iso20c_FWAtSalP02Sv.nc')\n",
    "iso_p02sv = iso_p02sv.sel(TIME=slice(cftime.DatetimeNoLeap(200, 1, 1, 0, 0),cftime.DatetimeNoLeap(501, 1, 1, 0, 0)))\n",
    "\n",
    "iso_p04sv = xr.open_dataset(f'{directory_data}iso20c_FWAtSalP04Sv.nc')\n",
    "iso_p04sv = iso_p04sv.sel(TIME=slice(cftime.DatetimeNoLeap(200, 1, 1, 0, 0),cftime.DatetimeNoLeap(501, 1, 1, 0, 0)))\n",
    "\n",
    "iso_psalt = xr.open_dataset(f'{directory_data}iso20c_FWPaSalP04Sv.nc')\n",
    "iso_psalt = iso_psalt.sel(TIME=slice(cftime.DatetimeNoLeap(100, 1, 1, 0, 0),cftime.DatetimeNoLeap(251, 1, 1, 0, 0)))\n",
    "\n",
    "iso_cntrl = xr.open_dataset(f'{directory_data}iso20c_005.nc')\n",
    "iso_cntrl = iso_cntrl.sel(TIME=slice(cftime.DatetimeNoLeap(800, 1, 1, 0, 0),cftime.DatetimeNoLeap(1600, 1, 1, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = enso.DefineNino(nino='nino34', lats='lat', lons='lon', cutoff=0.5, runningmean=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds2 = xr.open_mfdataset(f'{directory_data}{file_cntrl}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds2 = ds2.assign_coords(time=ds2.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds2 = ds2.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo\n",
    "control_ssts_roll = nino.monthly_climo(ds2['SST'].chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "control_nino = nino.compute_index(ds2['SST'], control_ssts_roll, \n",
    "                                  linear_detrend=False, lat_name='lat')\n",
    "\n",
    "control_nino = control_nino.sel(time=slice(iso_cntrl.TIME.values[0], iso_cntrl.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "control_index = control_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "controlnino, controlnina = grab_enso_spatial(\n",
    "                                              ds = iso_cntrl.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                              indices = control_index, \n",
    "                                              ds_oni = control_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 801, \n",
    "                                              year2 = 1599,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_g02sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo\n",
    "g02sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "g02sv_nino = nino.compute_index(ds1['SST'], g02sv_ssts_roll,\n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "\n",
    "g02sv_nino = g02sv_nino.sel(time=slice(iso_g02sv.TIME.values[0], iso_g02sv.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "g02sv_index = g02sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "g02svnino, g02svnina = grab_enso_spatial(\n",
    "                                          ds = iso_g02sv.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                          indices = g02sv_index, \n",
    "                                          ds_oni = g02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                          year1 = 201, \n",
    "                                          year2 = 500, \n",
    "                                          cutoff = nino.cutoff, \n",
    "                                          filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_g04sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo\n",
    "g04sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "g04sv_nino = nino.compute_index(ds1['SST'], g04sv_ssts_roll,\n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "\n",
    "g04sv_nino = g04sv_nino.sel(time=slice(iso_g04sv.TIME.values[0], iso_g04sv.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "g04sv_index = g04sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "g04svnino, g04svnina = grab_enso_spatial(\n",
    "                                          ds = iso_g04sv.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                          indices = g04sv_index, \n",
    "                                          ds_oni = g04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                          year1 = 201, \n",
    "                                          year2 = 500, \n",
    "                                          cutoff = nino.cutoff, \n",
    "                                          filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_p02sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo\n",
    "p02sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "p02sv_nino = nino.compute_index(ds1['SST'], p02sv_ssts_roll,\n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "\n",
    "p02sv_nino = p02sv_nino.sel(time=slice(iso_p02sv.TIME.values[0], iso_p02sv.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "p02sv_index = p02sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "p02svnino, p02svnina = grab_enso_spatial(\n",
    "                                          ds = iso_p02sv.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                          indices = p02sv_index, \n",
    "                                          ds_oni = p02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                          year1 = 201, \n",
    "                                          year2 = 500, \n",
    "                                          cutoff = nino.cutoff, \n",
    "                                          filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_p04sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo\n",
    "p04sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "p04sv_nino = nino.compute_index(ds1['SST'], p04sv_ssts_roll,\n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "\n",
    "p04sv_nino = p04sv_nino.sel(time=slice(iso_p04sv.TIME.values[0], iso_p04sv.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "p04sv_index = p04sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "p04svnino, p04svnina = grab_enso_spatial(\n",
    "                                          ds = iso_p04sv.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                          indices = p04sv_index, \n",
    "                                          ds_oni = p04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                          year1 = 201, \n",
    "                                          year2 = 500, \n",
    "                                          cutoff = nino.cutoff, \n",
    "                                          filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_psalt}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "# psalt index computation\n",
    "ds8 = xr.open_mfdataset(f'{directory_data}b2d.e11.B1850LENS.f09_g16.FWPaSalP04Sv.pop.h.SST.030101-035012.nc',\n",
    "                       combine='by_coords',\n",
    "                       preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds8 = ds8.assign_coords(time=ds8.coords['time'] - timedelta(days=17))\n",
    "ds8 = ds8.sel(time=slice('0301-01-01 00:00:00', '0351-01-01 00:00:00'))\n",
    "\n",
    "# attach first 100 years\n",
    "pnew = xr.concat([ds1['SST'].sel(time=slice('0001-01-01 00:00:00', '0301-01-01 00:00:00')).drop('z_t'),\n",
    "                  ds8['SST']], dim='time')\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "psalt_ssts_roll = nino.monthly_climo(pnew.chunk({'time':None}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "psalt_nino = nino.compute_index(pnew, psalt_ssts_roll, \n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "\n",
    "psalt_nino = psalt_nino.sel(time=slice(iso_psalt.TIME.values[0], iso_psalt.TIME.values[-1]))\n",
    "\n",
    "# grab numpy array\n",
    "psalt_index = psalt_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### TEMP\n",
    "\n",
    "psaltnino, psaltnina = grab_enso_spatial(\n",
    "                                          ds = iso_psalt.resample(TIME='QS-DEC').mean(skipna=True), \n",
    "                                          indices = psalt_index, \n",
    "                                          ds_oni = psalt_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                          year1 = 101, \n",
    "                                          year2 = 250, \n",
    "                                          cutoff = nino.cutoff, \n",
    "                                          filevar = THEDEPTH)\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:68: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "poplon = pop_lon_nino34()\n",
    "\n",
    "cntrl_diff_nino = compute_iso(controlnino.values, poplon)\n",
    "g02sv_diff_nino = compute_iso(g02svnino.values, poplon)\n",
    "g04sv_diff_nino = compute_iso(g04svnino.values, poplon)\n",
    "p02sv_diff_nino = compute_iso(p02svnino.values, poplon)\n",
    "p04sv_diff_nino = compute_iso(p04svnino.values, poplon)\n",
    "psalt_diff_nino = compute_iso(psaltnino.values, poplon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble=xr.Dataset({\n",
    "                 'cntrl_nino':(['a'], cntrl_diff_nino),\n",
    "                 'g02sv_nino':(['a'], g02sv_diff_nino),\n",
    "                 'g04sv_nino':(['a'], g04sv_diff_nino),\n",
    "                 'p02sv_nino':(['a'], p02sv_diff_nino),\n",
    "                 'p04sv_nino':(['a'], p04sv_diff_nino),\n",
    "                 'psalt_nino':(['a'], psalt_diff_nino)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble.to_netcdf(f'{directory_data}ninoslabs_{THEDEPTH}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/molina/miniconda3/envs/python-tutorial/lib/python3.7/site-packages/ipykernel_launcher.py:68: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "cntrl_diff_nina = compute_iso(controlnina.values, poplon)\n",
    "g02sv_diff_nina = compute_iso(g02svnina.values, poplon)\n",
    "g04sv_diff_nina = compute_iso(g04svnina.values, poplon)\n",
    "p02sv_diff_nina = compute_iso(p02svnina.values, poplon)\n",
    "p04sv_diff_nina = compute_iso(p04svnina.values, poplon)\n",
    "psalt_diff_nina = compute_iso(psaltnina.values, poplon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble=xr.Dataset({\n",
    "                 'cntrl_nina':(['a'], cntrl_diff_nina),\n",
    "                 'g02sv_nina':(['a'], g02sv_diff_nina),\n",
    "                 'g04sv_nina':(['a'], g04sv_diff_nina),\n",
    "                 'p02sv_nina':(['a'], p02sv_diff_nina),\n",
    "                 'p04sv_nina':(['a'], p04sv_diff_nina),\n",
    "                 'psalt_nina':(['a'], psalt_diff_nina)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble.to_netcdf(f'{directory_data}ninaslabs_{THEDEPTH}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-python-tutorial]",
   "language": "python",
   "name": "conda-env-miniconda3-python-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
