{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation for ENSO events and their spatial regions\n",
    "\n",
    "Compute ONI values, then extract corresponding tropical Pacific region SSTs for ENSO events. Save as netCDFs for future use. Save El Nino, La Nina, and corresponding experiment climatology (for computing ENSO event anomalies).\n",
    "\n",
    "**Figure by: Maria J. Molina, NCAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from climatico import enso\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "from climatico.util import weighted_mean, pacific_lon\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import directory_figs, directory_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_enso_spatial(ds, indices, ds_oni, year1, year2, cutoff, filevar='SST', quarter=12):\n",
    "    \"\"\"\n",
    "    Use the input seasonal file ('QS-DEC') and precomputed Nino-index to extract Nino(a) \n",
    "    event indices in time array of SST file.\n",
    "    Then extract the variable associated with the Nino(a) events. These focus on DJF months.\n",
    "    \n",
    "    Args:\n",
    "        ds (xarray data array): Seasonal variable to filter for plotting \n",
    "                                    (e.g., ds.resample(time='QS-DEC').mean(skipna=True)).\n",
    "        indices (numpy array): ONI values as numpy array \n",
    "                                    (e.g., control_nino.resample(time='QS-DEC').mean(skipna=True).values).\n",
    "        ds_oni (xarray data array): ONI seasonal xarray \n",
    "                                    (e.g., control_nino.resample(time='QS-DEC').mean(skipna=True)).\n",
    "        year1 (int): First year for range filtering.\n",
    "        year2 (int): Second year for range filtering.\n",
    "        cutoff (float): Cutoff of ENSO events. E.g., +/-0.5 for ONI.\n",
    "        filevar (str): Variable name for input ds. Defaults to ``SST.``\n",
    "        quarter (int): Month of quarter start (e.g., 12, 3, 6, 9).\n",
    "    \"\"\"\n",
    "    # do checks\n",
    "    check1 = ds[filevar].isel(time=np.where(indices>=cutoff)[0])[(ds[filevar].isel(time=np.where(indices>=cutoff)[0])['time'].dt.month==quarter)].coords['time']\n",
    "    check2 = ds_oni.isel(time=np.where(indices>=cutoff)[0])[(ds_oni.isel(time=np.where(indices>=cutoff)[0])['time'].dt.month==quarter)].coords['time']\n",
    "    assert np.all(check1.values==check2.values), \"Nino events don't match\"\n",
    "    print(\"Nino check passed\")\n",
    "    \n",
    "    check1 = ds[filevar].isel(time=np.where(indices<=cutoff)[0])[(ds[filevar].isel(time=np.where(indices<=cutoff)[0])['time'].dt.month==quarter)].coords['time']\n",
    "    check2 = ds_oni.isel(time=np.where(indices<=cutoff)[0])[(ds_oni.isel(time=np.where(indices<=cutoff)[0])['time'].dt.month==quarter)].coords['time']\n",
    "    assert np.all(check1.values==check2.values), \"Nina events don't match\"\n",
    "    print(\"Nina check passed\")\n",
    "    \n",
    "    ### climo\n",
    "    climatology = ds[filevar][(ds[filevar]['time'].dt.month==quarter)]\n",
    "    climatology = climatology[(climatology['time'].dt.year>=year1)&(climatology['time'].dt.year<=year2)]\n",
    "    climo = climatology.mean(dim='time')\n",
    "    \n",
    "    ### nino\n",
    "    # filter for djf quarters\n",
    "    sv_indices = ds[filevar].isel(time=np.where(indices>=cutoff)[0])[(ds[filevar].isel(time=np.where(indices>=cutoff)[0])['time'].dt.month==quarter)]\n",
    "    # filter for correct year range\n",
    "    sv_indices = sv_indices[(sv_indices['time'].dt.year>=year1)&(sv_indices['time'].dt.year<=year2)]\n",
    "    # take spatial mean for plotting\n",
    "    nino = sv_indices.mean(dim='time')\n",
    "    print(\"Nino done\")\n",
    "\n",
    "    ### nina\n",
    "    # filter for djf quarters\n",
    "    sv_indices = ds[filevar].isel(time=np.where(indices<=cutoff)[0])[(ds[filevar].isel(time=np.where(indices<=cutoff)[0])['time'].dt.month==quarter)]\n",
    "    # filter for correct year range\n",
    "    sv_indices = sv_indices[(sv_indices['time'].dt.year>=year1)&(sv_indices['time'].dt.year<=year2)]\n",
    "    # take spatial mean for plotting\n",
    "    nina = sv_indices.mean(dim='time')\n",
    "    print(\"Nina done\")\n",
    "    \n",
    "    return nino, nina, climo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of filenames to do this for:\n",
    "# SSTs\n",
    "file_g02sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalG02Sv.pop.h.SST.*.nc'\n",
    "file_g04sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalG04Sv.pop.h.SST.*.nc'\n",
    "file_p02sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalP02Sv.pop.h.SST.*.nc'\n",
    "file_p04sv = 'b1d.e11.B1850LENS.f09_g16.FWAtSalP04Sv.pop.h.SST.*.nc'\n",
    "file_psalt = 'b1d.e11.B1850LENS.f09_g16.FWPaSalP04Sv.pop.h.SST.*.nc'\n",
    "file_cntrl = 'b1d.e11.B1850C5CN.f09_g16.005.pop.h.SST.*.nc'\n",
    "# wind stress x-direction\n",
    "taux_g02sv = 'b.e11.B1850LENS.f09_g16.FWAtSalG02Sv.cam.h0.TAUX.*.nc'\n",
    "taux_g04sv = 'b.e11.B1850LENS.f09_g16.FWAtSalG04Sv.cam.h0.TAUX.*.nc'\n",
    "taux_p02sv = 'b.e11.B1850LENS.f09_g16.FWAtSalP02Sv.cam.h0.TAUX.*.nc'\n",
    "taux_p04sv = 'b.e11.B1850LENS.f09_g16.FWAtSalP04Sv.cam.h0.TAUX.*.nc'\n",
    "taux_psalt = 'b.e11.B1850LENS.f09_g16.FWPaSalP04Sv.cam.h0.TAUX.*.nc'\n",
    "taux_cntrl = 'b.e11.B1850C5CN.f09_g16.005.cam.h0.TAUX.*.nc'\n",
    "# wind stress y-direction\n",
    "tauy_g02sv = 'b.e11.B1850LENS.f09_g16.FWAtSalG02Sv.cam.h0.TAUY.*.nc'\n",
    "tauy_g04sv = 'b.e11.B1850LENS.f09_g16.FWAtSalG04Sv.cam.h0.TAUY.*.nc'\n",
    "tauy_p02sv = 'b.e11.B1850LENS.f09_g16.FWAtSalP02Sv.cam.h0.TAUY.*.nc'\n",
    "tauy_p04sv = 'b.e11.B1850LENS.f09_g16.FWAtSalP04Sv.cam.h0.TAUY.*.nc'\n",
    "tauy_psalt = 'b.e11.B1850LENS.f09_g16.FWPaSalP04Sv.cam.h0.TAUY.*.nc'\n",
    "tauy_cntrl = 'b.e11.B1850C5CN.f09_g16.005.cam.h0.TAUY.*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = enso.DefineNino(nino='nino34', lats='lat', lons='lon', cutoff=0.5, runningmean=3)\n",
    "ninoslab = enso.DefineNino(nino='pacslab', lats='lat', lons='lon', cutoff=0.5, runningmean=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds2 = xr.open_mfdataset(f'{directory_data}{file_cntrl}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds2 = ds2.assign_coords(time=ds2.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds2 = ds2.isel(z_t=0).sel(time=slice(cftime.DatetimeNoLeap(800, 1, 1, 0, 0),cftime.DatetimeNoLeap(1600, 1, 1, 0, 0)))\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "control_ssts_roll = nino.monthly_climo(ds2['SST'].chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "control_nino = nino.compute_index(ds2['SST'], control_ssts_roll, \n",
    "                                  linear_detrend=False, lat_name='lat')\n",
    "# compute indices (previously)\n",
    "#control_nino = nino.compute_index(ds2['SST'].groupby('time.month'), \n",
    "#                                  ds2['SST'].groupby('time.month').mean(skipna=True), \n",
    "#                                  linear_detrend=False, lat_name='lat')\n",
    "# grab numpy array\n",
    "control_index = control_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### sst\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_cntrl}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0).sel(time=slice(cftime.DatetimeNoLeap(800, 1, 1, 0, 0),cftime.DatetimeNoLeap(1600, 1, 1, 0, 0)))\n",
    "\n",
    "# ssts\n",
    "controlnino, controlnina, controlclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = control_index, \n",
    "                                              ds_oni = control_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 801, \n",
    "                                              year2 = 1599,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_cntrl}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dstx = dstx.sel(time=slice(cftime.DatetimeNoLeap(800, 1, 1, 0, 0),cftime.DatetimeNoLeap(1600, 1, 1, 0, 0)))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "controlninotx, controlninatx, controlclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = control_index, \n",
    "                                              ds_oni = control_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 801, \n",
    "                                              year2 = 1599,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUX')\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_cntrl}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsty = dsty.sel(time=slice(cftime.DatetimeNoLeap(800, 1, 1, 0, 0),cftime.DatetimeNoLeap(1600, 1, 1, 0, 0)))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "controlninoty, controlninaty, controlclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = control_index, \n",
    "                                              ds_oni = control_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 801, \n",
    "                                              year2 = 1599, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_g02sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "g02sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "g02sv_nino = nino.compute_index(ds1['SST'], g02sv_ssts_roll, \n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "# grab numpy array\n",
    "g02sv_index = g02sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### ssts\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_g02sv}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0)\n",
    "\n",
    "g02svnino, g02svnina, g02svclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g02sv_index, \n",
    "                                              ds_oni = g02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_g02sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "g02svninotx, g02svninatx, g02svclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g02sv_index,\n",
    "                                              ds_oni = g02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUX')\n",
    "\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_g02sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "g02svninoty, g02svninaty, g02svclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g02sv_index, \n",
    "                                              ds_oni = g02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_g04sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "g04sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "g04sv_nino = nino.compute_index(ds1['SST'], g04sv_ssts_roll,\n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "# grab numpy array\n",
    "g04sv_index = g04sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### ssts\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_g04sv}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0)\n",
    "\n",
    "g04svnino, g04svnina, g04svclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g04sv_index, \n",
    "                                              ds_oni = g04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_g04sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "g04svninotx, g04svninatx, g04svclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g04sv_index, \n",
    "                                              ds_oni = g04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUX')\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_g04sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "g04svninoty, g04svninaty, g04svclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = g04sv_index, \n",
    "                                              ds_oni = g04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_p02sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "p02sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "p02sv_nino = nino.compute_index(ds1['SST'], p02sv_ssts_roll, \n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "# grab numpy array\n",
    "p02sv_index = p02sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### ssts\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_p02sv}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0)\n",
    "\n",
    "p02svnino, p02svnina, p02svclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p02sv_index, \n",
    "                                              ds_oni = p02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_p02sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "p02svninotx, p02svninatx, p02svclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p02sv_index, \n",
    "                                              ds_oni = p02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUX')\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_p02sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "p02svninoty, p02svninaty, p02svclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p02sv_index, \n",
    "                                              ds_oni = p02sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_p04sv}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "p04sv_ssts_roll = nino.monthly_climo(ds1['SST'].chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "p04sv_nino = nino.compute_index(ds1['SST'], p04sv_ssts_roll, \n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "# grab numpy array\n",
    "p04sv_index = p04sv_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### ssts\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_p04sv}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0)\n",
    "\n",
    "p04svnino, p04svnina, p04svclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p04sv_index, \n",
    "                                              ds_oni = p04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_p04sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "p04svninotx, p04svninatx, p04svclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p04sv_index, \n",
    "                                              ds_oni = p04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar='TAUX')\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_p04sv}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "p04svninoty, p04svninaty, p04svclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = p04sv_index, \n",
    "                                              ds_oni = p04sv_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 201, \n",
    "                                              year2 = 500, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices started\n",
      "indices done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n",
      "Nino check passed\n",
      "Nina check passed\n",
      "Nino done\n",
      "Nina done\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "\n",
    "ds1 = xr.open_mfdataset(f'{directory_data}{file_psalt}',\n",
    "                        combine='by_coords',\n",
    "                        preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds1 = ds1.assign_coords(time=ds1.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "ds1 = ds1.isel(z_t=0)\n",
    "\n",
    "# psalt index computation\n",
    "ds8 = xr.open_mfdataset(f'{directory_data}b2d.e11.B1850LENS.f09_g16.FWPaSalP04Sv.pop.h.SST.030101-035012.nc',\n",
    "                       combine='by_coords',\n",
    "                       preprocess=nino.nino)\n",
    "# fix time coord\n",
    "ds8 = ds8.assign_coords(time=ds8.coords['time'] - timedelta(days=17))\n",
    "ds8 = ds8.sel(time=slice('0301-01-01 00:00:00', '0351-01-01 00:00:00'))\n",
    "\n",
    "# attach first 100 years\n",
    "pnew = xr.concat([ds1['SST'].sel(time=slice('0001-01-01 00:00:00', '0301-01-01 00:00:00')).drop('z_t'),\n",
    "                  ds8['SST']], dim='time')\n",
    "\n",
    "print(\"indices started\")\n",
    "# rolling climo \n",
    "psalt_ssts_roll = nino.monthly_climo(pnew.chunk({'time':900}), yrsroll=30, centered=True, time='time')\n",
    "# compute nino index\n",
    "psalt_nino = nino.compute_index(pnew, psalt_ssts_roll, \n",
    "                                linear_detrend=False, lat_name='lat')\n",
    "psalt_nino = psalt_nino.sel(time=slice('0001-01-01 00:00:00', '0301-01-01 00:00:00'))\n",
    "# grab numpy array\n",
    "psalt_index = psalt_nino.resample(time='QS-DEC').mean(skipna=True).values\n",
    "print(\"indices done\")\n",
    "\n",
    "#################################################################### ssts\n",
    "\n",
    "dsslab = xr.open_mfdataset(f'{directory_data}{file_psalt}',\n",
    "                            combine='by_coords',\n",
    "                            preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsslab = dsslab.assign_coords(time=dsslab.coords['time'] - timedelta(days=17))\n",
    "# reduce dims to time, lat, lon\n",
    "dsslab = dsslab.isel(z_t=0)\n",
    "\n",
    "psaltnino, psaltnina, psaltclimo = grab_enso_spatial(\n",
    "                                              ds = dsslab.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = psalt_index, \n",
    "                                              ds_oni = psalt_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 101, \n",
    "                                              year2 = 250, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'SST')\n",
    "\n",
    "#################################################################### taux\n",
    "\n",
    "dstx = xr.open_mfdataset(f'{directory_data}{taux_psalt}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dstx = dstx.assign_coords(time=dstx.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "psaltninotx, psaltninatx, psaltclimotx = grab_enso_spatial(\n",
    "                                              ds = dstx.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = psalt_index, \n",
    "                                              ds_oni = psalt_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 101, \n",
    "                                              year2 = 250, \n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUX')\n",
    "\n",
    "#################################################################### tauy\n",
    "\n",
    "dsty = xr.open_mfdataset(f'{directory_data}{tauy_psalt}',\n",
    "                         combine='by_coords',\n",
    "                         preprocess=ninoslab.nino)\n",
    "# fix time coord\n",
    "dsty = dsty.assign_coords(time=dsty.coords['time'] - timedelta(days=17))\n",
    "\n",
    "# grab enso mean spatial maps\n",
    "psaltninoty, psaltninaty, psaltclimoty = grab_enso_spatial(\n",
    "                                              ds = dsty.resample(time='QS-DEC').mean(skipna=True), \n",
    "                                              indices = psalt_index, \n",
    "                                              ds_oni = psalt_nino.resample(time='QS-DEC').mean(skipna=True),\n",
    "                                              year1 = 101, \n",
    "                                              year2 = 250,\n",
    "                                              cutoff = nino.cutoff, \n",
    "                                              filevar = 'TAUY')\n",
    "\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cntrl_diff_nino = controlnino.values\n",
    "cntrl_diff_ninotx = np.negative(controlninotx).values\n",
    "cntrl_diff_ninoty = np.negative(controlninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g02sv_diff_nino = g02svnino.values\n",
    "g02sv_diff_ninotx = np.negative(g02svninotx).values\n",
    "g02sv_diff_ninoty = np.negative(g02svninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g04sv_diff_nino = g04svnino.values\n",
    "g04sv_diff_ninotx = np.negative(g04svninotx).values\n",
    "g04sv_diff_ninoty = np.negative(g04svninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p02sv_diff_nino = p02svnino.values\n",
    "p02sv_diff_ninotx = np.negative(p02svninotx).values\n",
    "p02sv_diff_ninoty = np.negative(p02svninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p04sv_diff_nino = p04svnino.values\n",
    "p04sv_diff_ninotx = np.negative(p04svninotx).values\n",
    "p04sv_diff_ninoty = np.negative(p04svninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "psalt_diff_nino = psaltnino.values\n",
    "psalt_diff_ninotx = np.negative(psaltninotx).values\n",
    "psalt_diff_ninoty = np.negative(psaltninoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble=xr.Dataset({\n",
    "    \n",
    "                 'cntrl_diff_nino':(['ssty','sstx'], cntrl_diff_nino),\n",
    "                 'cntrl_diff_ninotx':(['y','x'], cntrl_diff_ninotx),\n",
    "                 'cntrl_diff_ninoty':(['y','x'], cntrl_diff_ninoty),\n",
    "    \n",
    "                 'g02sv_diff_nino':(['ssty','sstx'], g02sv_diff_nino),\n",
    "                 'g02sv_diff_ninotx':(['y','x'], g02sv_diff_ninotx),\n",
    "                 'g02sv_diff_ninoty':(['y','x'], g02sv_diff_ninoty),\n",
    "    \n",
    "                 'g04sv_diff_nino':(['ssty','sstx'], g04sv_diff_nino),\n",
    "                 'g04sv_diff_ninotx':(['y','x'], g04sv_diff_ninotx),\n",
    "                 'g04sv_diff_ninoty':(['y','x'], g04sv_diff_ninoty),\n",
    "    \n",
    "                 'p02sv_diff_nino':(['ssty','sstx'], p02sv_diff_nino),\n",
    "                 'p02sv_diff_ninotx':(['y','x'], p02sv_diff_ninotx),\n",
    "                 'p02sv_diff_ninoty':(['y','x'], p02sv_diff_ninoty),\n",
    "    \n",
    "                 'p04sv_diff_nino':(['ssty','sstx'], p04sv_diff_nino),\n",
    "                 'p04sv_diff_ninotx':(['y','x'], p04sv_diff_ninotx),\n",
    "                 'p04sv_diff_ninoty':(['y','x'], p04sv_diff_ninoty),\n",
    "    \n",
    "                 'psalt_diff_nino':(['ssty','sstx'], psalt_diff_nino),\n",
    "                 'psalt_diff_ninotx':(['y','x'], psalt_diff_ninotx),\n",
    "                 'psalt_diff_ninoty':(['y','x'], psalt_diff_ninoty),\n",
    "    \n",
    "                },\n",
    "                 coords=\n",
    "                {'lon':(['sstx'], controlnino.coords['lon'].values),\n",
    "                 'lat':(['ssty'], controlnino.coords['lat'].values),\n",
    "                 'lons':(['x'], controlninotx.coords['lon'].values),\n",
    "                 'lats':(['y'], controlninotx.coords['lat'].values)\n",
    "                })     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble.to_netcdf(f'{directory_data}fig10_ninodata.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cntrl_diff_nina = controlnina.values\n",
    "cntrl_diff_ninatx = np.negative(controlninatx).values\n",
    "cntrl_diff_ninaty = np.negative(controlninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g02sv_diff_nina = g02svnina.values\n",
    "g02sv_diff_ninatx = np.negative(g02svninatx).values\n",
    "g02sv_diff_ninaty = np.negative(g02svninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g04sv_diff_nina = g04svnina.values\n",
    "g04sv_diff_ninatx = np.negative(g04svninatx).values\n",
    "g04sv_diff_ninaty = np.negative(g04svninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p02sv_diff_nina = p02svnina.values\n",
    "p02sv_diff_ninatx = np.negative(p02svninatx).values\n",
    "p02sv_diff_ninaty = np.negative(p02svninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p04sv_diff_nina = p04svnina.values\n",
    "p04sv_diff_ninatx = np.negative(p04svninatx).values\n",
    "p04sv_diff_ninaty = np.negative(p04svninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "psalt_diff_nina = psaltnina.values\n",
    "psalt_diff_ninatx = np.negative(psaltninatx).values\n",
    "psalt_diff_ninaty = np.negative(psaltninaty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble=xr.Dataset({\n",
    "    \n",
    "                 'cntrl_diff_nina':(['ssty','sstx'], cntrl_diff_nina),\n",
    "                 'cntrl_diff_ninatx':(['y','x'], cntrl_diff_ninatx),\n",
    "                 'cntrl_diff_ninaty':(['y','x'], cntrl_diff_ninaty),\n",
    "    \n",
    "                 'g02sv_diff_nina':(['ssty','sstx'], g02sv_diff_nina),\n",
    "                 'g02sv_diff_ninatx':(['y','x'], g02sv_diff_ninatx),\n",
    "                 'g02sv_diff_ninaty':(['y','x'], g02sv_diff_ninaty),\n",
    "    \n",
    "                 'g04sv_diff_nina':(['ssty','sstx'], g04sv_diff_nina),\n",
    "                 'g04sv_diff_ninatx':(['y','x'], g04sv_diff_ninatx),\n",
    "                 'g04sv_diff_ninaty':(['y','x'], g04sv_diff_ninaty),\n",
    "    \n",
    "                 'p02sv_diff_nina':(['ssty','sstx'], p02sv_diff_nina),\n",
    "                 'p02sv_diff_ninatx':(['y','x'], p02sv_diff_ninatx),\n",
    "                 'p02sv_diff_ninaty':(['y','x'], p02sv_diff_ninaty),\n",
    "    \n",
    "                 'p04sv_diff_nina':(['ssty','sstx'], p04sv_diff_nina),\n",
    "                 'p04sv_diff_ninatx':(['y','x'], p04sv_diff_ninatx),\n",
    "                 'p04sv_diff_ninaty':(['y','x'], p04sv_diff_ninaty),\n",
    "    \n",
    "                 'psalt_diff_nina':(['ssty','sstx'], psalt_diff_nina),\n",
    "                 'psalt_diff_ninatx':(['y','x'], psalt_diff_ninatx),\n",
    "                 'psalt_diff_ninaty':(['y','x'], psalt_diff_ninaty),\n",
    "    \n",
    "                },\n",
    "                 coords=\n",
    "                {'lon':(['sstx'], controlnina.coords['lon'].values),\n",
    "                 'lat':(['ssty'], controlnina.coords['lat'].values),\n",
    "                 'lons':(['x'], controlninatx.coords['lon'].values),\n",
    "                 'lats':(['y'], controlninatx.coords['lat'].values)\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble.to_netcdf(f'{directory_data}fig11_ninadata.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cntrl_diff_climo = controlclimo.values\n",
    "cntrl_diff_climotx = np.negative(controlclimotx).values\n",
    "cntrl_diff_climoty = np.negative(controlclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g02sv_diff_climo = g02svclimo.values\n",
    "g02sv_diff_climotx = np.negative(g02svclimotx).values\n",
    "g02sv_diff_climoty = np.negative(g02svclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "g04sv_diff_climo = g04svclimo.values\n",
    "g04sv_diff_climotx = np.negative(g04svclimotx).values\n",
    "g04sv_diff_climoty = np.negative(g04svclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p02sv_diff_climo = p02svclimo.values\n",
    "p02sv_diff_climotx = np.negative(p02svclimotx).values\n",
    "p02sv_diff_climoty = np.negative(p02svclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "p04sv_diff_climo = p04svclimo.values\n",
    "p04sv_diff_climotx = np.negative(p04svclimotx).values\n",
    "p04sv_diff_climoty = np.negative(p04svclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "psalt_diff_climo = psaltclimo.values\n",
    "psalt_diff_climotx = np.negative(psaltclimotx).values\n",
    "psalt_diff_climoty = np.negative(psaltclimoty).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble=xr.Dataset({\n",
    "    \n",
    "                 'cntrl_diff_climo':(['ssty','sstx'], cntrl_diff_climo),\n",
    "                 'cntrl_diff_climotx':(['y','x'], cntrl_diff_climotx),\n",
    "                 'cntrl_diff_climoty':(['y','x'], cntrl_diff_climoty),\n",
    "    \n",
    "                 'g02sv_diff_climo':(['ssty','sstx'], g02sv_diff_climo),\n",
    "                 'g02sv_diff_climotx':(['y','x'], g02sv_diff_climotx),\n",
    "                 'g02sv_diff_climoty':(['y','x'], g02sv_diff_climoty),\n",
    "    \n",
    "                 'g04sv_diff_climo':(['ssty','sstx'], g04sv_diff_climo),\n",
    "                 'g04sv_diff_climotx':(['y','x'], g04sv_diff_climotx),\n",
    "                 'g04sv_diff_climoty':(['y','x'], g04sv_diff_climoty),\n",
    "    \n",
    "                 'p02sv_diff_climo':(['ssty','sstx'], p02sv_diff_climo),\n",
    "                 'p02sv_diff_climotx':(['y','x'], p02sv_diff_climotx),\n",
    "                 'p02sv_diff_climoty':(['y','x'], p02sv_diff_climoty),\n",
    "    \n",
    "                 'p04sv_diff_climo':(['ssty','sstx'], p04sv_diff_climo),\n",
    "                 'p04sv_diff_climotx':(['y','x'], p04sv_diff_climotx),\n",
    "                 'p04sv_diff_climoty':(['y','x'], p04sv_diff_climoty),\n",
    "    \n",
    "                 'psalt_diff_climo':(['ssty','sstx'], psalt_diff_climo),\n",
    "                 'psalt_diff_climotx':(['y','x'], psalt_diff_climotx),\n",
    "                 'psalt_diff_climoty':(['y','x'], psalt_diff_climoty),\n",
    "    \n",
    "                },\n",
    "                 coords=\n",
    "                {'lon':(['sstx'], controlclimo.coords['lon'].values),\n",
    "                 'lat':(['ssty'], controlclimo.coords['lat'].values),\n",
    "                 'lons':(['x'], controlclimotx.coords['lon'].values),\n",
    "                 'lats':(['y'], controlclimotx.coords['lat'].values)\n",
    "                })     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assemble.to_netcdf(f'{directory_data}fig11_climodata.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-python-tutorial]",
   "language": "python",
   "name": "conda-env-miniconda3-python-tutorial-python3_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
